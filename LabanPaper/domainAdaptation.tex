\subsection{Domain Adaptation}
In this experiment the test set was taken from a CMA that didn't appear in
the train set. As it shown in table \ref{domainAdaptationBaseLine}, there is a
dramatic degradation in the performance on the new CMA.  
 \begin{table}[H]
  	\centering
	\begin{tabular}{|p{1.8cm}|p{1.8cm}|p{1.8cm}|}
	\hline
	Metric&Average Score&Standard deviation\\\hline
	Precision&0.41&0.053\\\hline
	Recall&0.53&0.089\\\hline
	F1&0.457&0.064\\\hline
	\end{tabular}
	\caption{Qualities detection performance on a never seen subject. In every
	trial one CMA was the test set, while the classifier was learned from the
rest of the CMAs.}
   \label{domainAdaptationBaseLine}
\end{table}
We blame the degradation on the great variability that we got between clips from
one CMA to others. Every CMA performed different gestures, in different postures
(some sitting while some standing) and in different context (some were dancing
while some where acting).
This great variability motivated us to work in Domain Adaptation (DA) setting.
\subsubsection{Problem Setting}
As it was stated by Bickel et al. \cite{Bickel}, in the DA problem setting, a
labeled training sample:
\\ $L = <(x_1; y_1),\ldots,(x_m; y_m)>$ is available.
This training sample is governed by an unknown distribution $p(x|\lambda)$, labels
are drawn according to an unknown target concept $p(y|x)$. In addition, an unlabeled test set: 
$T = <xm+1,\ldots,xm+ni>$ becomes available. The test set is governed by a
different unknown distribution, $p(x|\theta)$. Training and test distribution
may differ arbitrarily, but there is only one unknown
target conditional class distribution $p(y|x)$.
\subsubsection{Instance  Weighting}
We denote our labeled source's domain dataset as the tuple $(X_{source},
Y_{source})$ of length $m$, our unlabeled target's dataset of
length $n$ as $X_{target}$, and the concatenation of $X_{source}$ and
$X_{target}$ as $X$, and we will define $R_{(m+n) \times t}$ such as:
\[
    R_{i,j}=
\begin{cases}
    0,& \text{if } 0<i \leq m\\
    1,& \text{if }  m < i \leq m+n
\end{cases}
\]
i.e. $R$ assigns 0 for every source's sample and 1 for very target's in every
task.

If $t$ is number of tasks that we handle and $d$ is our input dimension,
except to the mulititask classifier $W_{d \times t}$, we will learn an instance
weighting matrix $V_{d \times t}$, that will be a regressor that will assign a
weight for every instance in \testbf{every task}. i.e. for a sample as a column vector $x_i$, the
product $x_i\cdot V$ will give us a vector of length t that represents the
importance of that sample for every task. 
\\When inserting $V$ to the multitask
elastic net framework, we get:
\\\textbf{Optimization Problem: }\textit{Over all W, and V, minimize:}
\begin{equation*}
\begin{split}
	&\|X_{source}V(Y_{source} - X_{source}W)\|^2_F 
	\\&+ \lambda_1\cdot\|W\|_{2,1}
	\\&+\lambda_2\cdot\|W\|^2_F
	\\&+\lambda_3\cdot\|XV-R\|^2_F
\end{split}
\end{equation*}
i.e. learning both of the classifier and the instance weighting for all
of the tasks together.